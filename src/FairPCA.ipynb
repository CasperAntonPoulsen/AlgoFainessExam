{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)  # sets the max\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "rs = 1  # random state seed for reproducibility\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair PCA Experiments\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Functions\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_PCA(X, protected_features, n_components):\n",
    "\n",
    "    Z = np.copy(protected_features)\n",
    "\n",
    "    # Removing the mean from the protected features\n",
    "    Z = Z-np.mean(Z)\n",
    "\n",
    "    # Finding the orthonormal null-space spanned by Z^t X\n",
    "\n",
    "    R = scipy.linalg.null_space(np.matmul(Z.T, X))\n",
    "    \n",
    "    # Finding the orthonormal eigenvectors of R^T X^T X R\n",
    "    vals, L = scipy.linalg.eig(np.linalg.multi_dot([np.transpose(R), np.transpose(X), X, R]))\n",
    "\n",
    "    #sort by eigen values\n",
    "    idx = vals.argsort()[::-1]\n",
    "    L = L[:,idx]\n",
    "\n",
    "\n",
    "    # Finding the projection matrix\n",
    "    U = np.matmul(R, L[:n_components])\n",
    "\n",
    "    # Projecting our data into fair space and returning X'\n",
    "    return U, np.matmul(np.transpose(U),np.transpose(X))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness metrics (Equalized odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr_and_tpr(cm):\n",
    "    TN = cm[0][0]\n",
    "    FN = cm[1][0]\n",
    "    FP = cm[0][1]\n",
    "    TP = cm[1][1]\n",
    "\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = FP/(FP+TN)\n",
    "\n",
    "    return FPR, TPR\n",
    "\n",
    "def equalized_odds(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        groups,\n",
    "        group_protected,\n",
    "        group_non_protected\n",
    "    ):\n",
    "    \n",
    "    X_protected = X[groups == group_protected]\n",
    "    y_protected = y[groups == group_protected]\n",
    "    predictions_protected = model.predict(X_protected)\n",
    "\n",
    "\n",
    "    X_non_protected = X[groups == group_non_protected]\n",
    "    y_non_protected = y[groups == group_non_protected]\n",
    "    predictions_non_protected = model.predict(X_non_protected)\n",
    "\n",
    "    cm_protected = confusion_matrix(y_protected, predictions_protected)\n",
    "    cm_non_protected = confusion_matrix(y_non_protected, predictions_non_protected)\n",
    "\n",
    "    FPR_protected, TPR_protected = fpr_and_tpr(cm_protected)\n",
    "    FPR_non_protected, TPR_non_protected = fpr_and_tpr(cm_non_protected)\n",
    "\n",
    "    return pd.DataFrame({\"FPR\":[FPR_protected, FPR_non_protected], \"TPR\":[TPR_protected,TPR_non_protected]}, index=[group_protected,group_non_protected])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main experiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(\n",
    "            self, \n",
    "            data,\n",
    "            course,\n",
    "            grade_threshold,\n",
    "            test_ratio,\n",
    "            random_state\n",
    "        ):\n",
    "\n",
    "        self.course = course\n",
    "        self.random_state = random_state\n",
    "        self.test_ratio = test_ratio\n",
    "\n",
    "        self.data = data[data[\"course\"] == self.course]\n",
    "\n",
    "        self.target = data[data[\"course\"] == self.course][\"G3\"].apply(lambda x: 0 if x < grade_threshold else 1)\n",
    "\n",
    "        self.groups = data[data[\"course\"] == self.course][\"SES\"]\n",
    "\n",
    "        self.protected_variables = [\n",
    "            \"internet\",\n",
    "            \"traveltime\",\n",
    "            \"address\",\n",
    "            \"Mjob\",\n",
    "            \"Fjob\",\n",
    "            \"Medu\",\n",
    "            \"Fedu\",\n",
    "            \"SES\"\n",
    "        ]\n",
    "\n",
    "        _groups_and_protected = data[data[\"course\"] == self.course][self.protected_variables]\n",
    "        self.groups_and_protected = pd.get_dummies(\n",
    "            _groups_and_protected,\n",
    "            prefix=None,\n",
    "            prefix_sep=\"_\",\n",
    "            dummy_na=False,\n",
    "            columns=[\n",
    "                \"traveltime\",\n",
    "                \"address\",\n",
    "                \"Mjob\",\n",
    "                \"Fjob\",\n",
    "                \"Medu\",\n",
    "                \"Fedu\"\n",
    "            ],\n",
    "            drop_first=False\n",
    "        )\n",
    "\n",
    "        self.standard_scaler = StandardScaler()\n",
    "\n",
    "    def baseline_data_prep(self):\n",
    "\n",
    "        one_hot_cols =[\n",
    "            \"school\",\n",
    "            \"sex\",\n",
    "            \"age\",\n",
    "            \"address\",\n",
    "            \"famsize\",\n",
    "            \"Pstatus\",\n",
    "            \"Mjob\",\n",
    "            \"Fjob\",\n",
    "            \"reason\",\n",
    "            \"guardian\"\n",
    "        ]\n",
    "\n",
    "        _data = pd.get_dummies(\n",
    "                self.data,\n",
    "                prefix=None,\n",
    "                prefix_sep=\"_\",\n",
    "                dummy_na=False,  # dont add a column for missing values\n",
    "                columns=one_hot_cols,  # the columns we create the dummies for\n",
    "                drop_first=True,  # IMPORTANT to have true! removes the first dummy indicator. This is done to avoid multicollinearity. The category removed is indicated when all other dummy categories are 0.\n",
    "            )\n",
    "\n",
    "        _data = _data.replace({\n",
    "            \"schoolsup\": {\"no\":False, \"yes\":True},\n",
    "            \"famsup\": {\"no\":False, \"yes\":True},\n",
    "            \"paid\": {\"no\":False, \"yes\":True},\n",
    "            \"activities\": {\"no\":False, \"yes\":True},\n",
    "            \"nursery\": {\"no\":False, \"yes\":True},\n",
    "            \"higher\": {\"no\":False, \"yes\":True},\n",
    "            \"internet\": {\"no\":False, \"yes\":True},\n",
    "            \"romantic\": {\"no\":False, \"yes\":True},\n",
    "        })\n",
    "\n",
    "        _data = _data[_data[\"course\"] == self.course][[\n",
    "            'Medu', 'Fedu', 'traveltime', 'studytime', 'failures',\n",
    "            'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher',\n",
    "            'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc',\n",
    "            'health', 'absences', 'school_MS', 'sex_M', 'age_16',\n",
    "            'age_17', 'age_18', 'age_19', 'age_20', 'age_21', 'age_22', 'address_U',\n",
    "            'famsize_LE3', 'Pstatus_T', 'Mjob_health', 'Mjob_other',\n",
    "            'Mjob_services', 'Mjob_teacher', 'Fjob_health', 'Fjob_other',\n",
    "            'Fjob_services', 'Fjob_teacher', 'reason_home', 'reason_other',\n",
    "            'reason_reputation', 'guardian_mother', 'guardian_other'\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, self.group_train, self.group_test = train_test_split(\n",
    "            _data,\n",
    "            self.target,\n",
    "            self.groups,\n",
    "            test_size=self.test_ratio,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "\n",
    "\n",
    "    def no_protected_data_prep(self):\n",
    "\n",
    "        one_hot_cols =[\n",
    "            \"school\",\n",
    "            \"age\",\n",
    "            \"famsize\",\n",
    "            \"Pstatus\",\n",
    "            \"reason\",\n",
    "            \"guardian\"\n",
    "        ]\n",
    "\n",
    "        _data = pd.get_dummies(\n",
    "                self.data,\n",
    "                prefix=None,\n",
    "                prefix_sep=\"_\",\n",
    "                dummy_na=False,  # dont add a column for missing values\n",
    "                columns=one_hot_cols,  # the columns we create the dummies for\n",
    "                drop_first=True,  # IMPORTANT to have true! removes the first dummy indicator. This is done to avoid multicollinearity. The category removed is indicated when all other dummy categories are 0.\n",
    "            )\n",
    "\n",
    "        _data = _data.replace({\n",
    "            \"schoolsup\": {\"no\":False, \"yes\":True},\n",
    "            \"famsup\": {\"no\":False, \"yes\":True},\n",
    "            \"paid\": {\"no\":False, \"yes\":True},\n",
    "            \"activities\": {\"no\":False, \"yes\":True},\n",
    "            \"nursery\": {\"no\":False, \"yes\":True},\n",
    "            \"higher\": {\"no\":False, \"yes\":True},\n",
    "            \"romantic\": {\"no\":False, \"yes\":True},\n",
    "        })\n",
    "\n",
    "        _data = _data[_data[\"course\"] == self.course][[\n",
    "            'studytime', 'failures','schoolsup', 'famsup', 'paid', 'activities', \n",
    "            'nursery', 'higher', 'romantic', 'famrel', 'freetime',\n",
    "            'goout', 'Dalc', 'Walc', 'health', 'absences', 'school_MS', 'age_16',\n",
    "            'age_17', 'age_18', 'age_19', 'age_20', 'age_21', 'age_22', \n",
    "            'famsize_LE3', 'Pstatus_T', 'reason_home', 'reason_other',\n",
    "            'reason_reputation', 'guardian_mother', 'guardian_other'\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, self.group_train, self.group_test = train_test_split(\n",
    "            _data,\n",
    "            self.target,\n",
    "            self.groups,\n",
    "            test_size=self.test_ratio,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "\n",
    "\n",
    "    def fair_pca_data_prep(self):\n",
    "        one_hot_cols =[\n",
    "            \"school\",\n",
    "            \"age\",\n",
    "            \"famsize\",\n",
    "            \"Pstatus\",\n",
    "            \"reason\",\n",
    "            \"guardian\"\n",
    "        ]\n",
    "\n",
    "        _data = pd.get_dummies(\n",
    "                self.data,\n",
    "                prefix=None,\n",
    "                prefix_sep=\"_\",\n",
    "                dummy_na=False,  # dont add a column for missing values\n",
    "                columns=one_hot_cols,  # the columns we create the dummies for\n",
    "                drop_first=True,  # IMPORTANT to have true! removes the first dummy indicator. This is done to avoid multicollinearity. The category removed is indicated when all other dummy categories are 0.\n",
    "            )\n",
    "\n",
    "        _data = _data.replace({\n",
    "            \"schoolsup\": {\"no\":False, \"yes\":True},\n",
    "            \"famsup\": {\"no\":False, \"yes\":True},\n",
    "            \"paid\": {\"no\":False, \"yes\":True},\n",
    "            \"activities\": {\"no\":False, \"yes\":True},\n",
    "            \"nursery\": {\"no\":False, \"yes\":True},\n",
    "            \"higher\": {\"no\":False, \"yes\":True},\n",
    "            \"romantic\": {\"no\":False, \"yes\":True},\n",
    "        })\n",
    "\n",
    "        _data = _data[_data[\"course\"] == self.course][[\n",
    "            'studytime', 'failures','schoolsup', 'famsup', 'paid', 'activities', \n",
    "            'nursery', 'higher', 'romantic', 'famrel', 'freetime',\n",
    "            'goout', 'Dalc', 'Walc', 'health', 'absences', 'school_MS', 'age_16',\n",
    "            'age_17', 'age_18', 'age_19', 'age_20', 'age_21', 'age_22', \n",
    "            'famsize_LE3', 'Pstatus_T', 'reason_home', 'reason_other',\n",
    "            'reason_reputation', 'guardian_mother', 'guardian_other'\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, self.group_train, self.group_test = train_test_split(\n",
    "            _data,\n",
    "            self.target,\n",
    "            self.groups_and_protected,\n",
    "            test_size=self.test_ratio,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "\n",
    "\n",
    "    def train_and_test(\n",
    "            self,\n",
    "            model,\n",
    "            model_parameters,\n",
    "            eval\n",
    "        ):\n",
    "\n",
    "        _clf = model(random_state=self.random_state)\n",
    "        self.clf = GridSearchCV(_clf, model_parameters, scoring=eval)\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "\n",
    "        \n",
    "        self.predictions = self.clf.predict(self.X_test)\n",
    "\n",
    "        self.performance_metrics = {\n",
    "            \"accuracy\":accuracy_score(self.y_test, self.predictions),\n",
    "            \"recall\":recall_score(self.y_test, self.predictions),\n",
    "            \"f1\":f1_score(self.y_test, self.predictions)\n",
    "        }\n",
    "\n",
    "        self.fairness_metrics = equalized_odds(\n",
    "            self.clf, \n",
    "            self.X_test,\n",
    "            self.y_test,\n",
    "            self.group_test,\n",
    "            group_protected=\"lower\",\n",
    "            group_non_protected=\"middle/rich\"\n",
    "        )\n",
    "\n",
    "#        print(self.performance_metrics)\n",
    "#        print(self.fairness_metrics)\n",
    "\n",
    "    def apply_fairpca(\n",
    "            self,\n",
    "            protected_features\n",
    "        ):\n",
    "        \n",
    "        _X_train_standardized = self.standard_scaler.fit_transform(self.X_train)\n",
    "\n",
    "\n",
    "        self.n_principal_components = _X_train_standardized.shape[1]\n",
    "\n",
    "        self.projection_matrix, self.components_train = fair_PCA(_X_train_standardized, protected_features.to_numpy(), self.n_principal_components)\n",
    "\n",
    "\n",
    "    def train_and_test_pca(\n",
    "            self,\n",
    "            model,\n",
    "            model_parameters,\n",
    "            eval,\n",
    "            protected_features_to_suppress\n",
    "        ):\n",
    "        \n",
    "        _clf = model(random_state=self.random_state)\n",
    "        self.clf = GridSearchCV(_clf, model_parameters, scoring=eval)\n",
    "\n",
    "\n",
    "        _features_to_suppress = self.group_train[protected_features_to_suppress].replace({\"SES\":{\"lower\":0,\"middle/rich\":1}})\n",
    "\n",
    "        self.apply_fairpca(\n",
    "            _features_to_suppress\n",
    "        )\n",
    "\n",
    "\n",
    "        self.clf.fit(self.components_train.T, self.y_train)\n",
    "\n",
    "        _X_test_standard = self.standard_scaler.transform(self.X_test)\n",
    "\n",
    "        self.components_test = np.matmul(_X_test_standard, self.projection_matrix)\n",
    "        self.predictions = self.clf.predict(self.components_test)\n",
    "\n",
    "        self.performance_metrics = {\n",
    "            \"accuracy\":accuracy_score(self.y_test, self.predictions),\n",
    "            \"recall\":recall_score(self.y_test, self.predictions),\n",
    "            \"f1\":f1_score(self.y_test, self.predictions)\n",
    "        }\n",
    "\n",
    "        self.fairness_metrics = equalized_odds(\n",
    "            self.clf, \n",
    "            self.components_test,\n",
    "            self.y_test,\n",
    "            self.group_test[\"SES\"],\n",
    "            group_protected=\"lower\",\n",
    "            group_non_protected=\"middle/rich\"\n",
    "        )\n",
    "\n",
    "#        print(self.performance_metrics)\n",
    "#        print(self.fairness_metrics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all experiments function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(\n",
    "        data,\n",
    "        grade_thresholds,\n",
    "        test_ratio,\n",
    "        random_state,\n",
    "        model,\n",
    "        parameters,\n",
    "        eval,\n",
    "        proxies_to_suppress\n",
    "    ):\n",
    "\n",
    "    courses = [\"math\", \"portuguese\"]\n",
    "\n",
    "    experiments = list()\n",
    "\n",
    "    \n",
    "    for grade in grade_thresholds:\n",
    "        for course in courses:\n",
    "\n",
    "            # Baseline\n",
    "            experiment = Experiment(\n",
    "                data = data, \n",
    "                course = course, \n",
    "                grade_threshold = grade, \n",
    "                test_ratio = test_ratio, \n",
    "                random_state = random_state\n",
    "            )\n",
    "            experiment.baseline_data_prep()\n",
    "            experiment.train_and_test(\n",
    "                model = model, \n",
    "                model_parameters= parameters,\n",
    "                eval=eval\n",
    "            )\n",
    "\n",
    "\n",
    "            experiments.append({\n",
    "                \"name\":\"baseline\",\n",
    "                \"grade_threshold\":grade,\n",
    "                \"course\":course,\n",
    "                \"model\":experiment.clf,\n",
    "                \"performance_metrics\":experiment.performance_metrics,\n",
    "                \"fairness_metrics\":experiment.fairness_metrics,\n",
    "                \"experiment_object\":experiment,\n",
    "                \"suppressed_variables\":None\n",
    "            })\n",
    "\n",
    "            # print(experiments[-1][\"name\"])\n",
    "            # print(f\"course: {course}, grade_threshold: {grade}\")\n",
    "            # print(f\"peformance: {experiment.performance_metrics}\")\n",
    "            # print(f\"fairness:   {experiment.fairness_metrics}\")\n",
    "            # print(f\"suppressed proxies {None}\")\n",
    "            # print()\n",
    "\n",
    "            # No proxies\n",
    "            experiment = Experiment(\n",
    "                data = data, \n",
    "                course = course, \n",
    "                grade_threshold = grade, \n",
    "                test_ratio = test_ratio, \n",
    "                random_state = random_state\n",
    "            )\n",
    "            experiment.no_protected_data_prep()\n",
    "            experiment.train_and_test(\n",
    "                model = model, \n",
    "                model_parameters= parameters,\n",
    "                eval=eval\n",
    "            )\n",
    "\n",
    "            experiments.append({\n",
    "                \"name\":\"no_proxies\",\n",
    "                \"grade_threshold\":grade,\n",
    "                \"course\":course,\n",
    "                \"model\":experiment.clf,\n",
    "                \"performance_metrics\":experiment.performance_metrics,\n",
    "                \"fairness_metrics\":experiment.fairness_metrics,\n",
    "                \"experiment_object\":experiment,\n",
    "                \"suppressed_variables\":None\n",
    "            })\n",
    "\n",
    "            # print(experiments[-1][\"name\"])\n",
    "            # print(f\"course: {course}, grade_threshold: {grade}\")\n",
    "            # print(f\"peformance: {experiment.performance_metrics}\")\n",
    "            # print(f\"fairness:   {experiment.fairness_metrics}\")\n",
    "            # print(f\"suppressed proxies {None}\")\n",
    "            # print()\n",
    "\n",
    "            # Fair PCA Gradual\n",
    "\n",
    "            currently_suppressed = list()\n",
    "\n",
    "            for proxy in proxies_to_suppress:\n",
    "\n",
    "                currently_suppressed.append(proxy)\n",
    "\n",
    "                experiment = Experiment(\n",
    "                    data = data, \n",
    "                    course = course, \n",
    "                    grade_threshold = grade, \n",
    "                    test_ratio = test_ratio, \n",
    "                    random_state = random_state\n",
    "                )\n",
    "                experiment.fair_pca_data_prep()\n",
    "                experiment.train_and_test_pca(\n",
    "                    model = model, \n",
    "                    model_parameters= parameters,\n",
    "                    eval=eval,\n",
    "                    protected_features_to_suppress=currently_suppressed\n",
    "                )\n",
    "\n",
    "                output_proxies = [i for i in currently_suppressed]\n",
    "\n",
    "                experiments.append({\n",
    "                    \"name\":\"fairpca\",\n",
    "                    \"grade_threshold\":grade,\n",
    "                    \"course\":course,\n",
    "                    \"model\":experiment.clf,\n",
    "                    \"performance_metrics\":experiment.performance_metrics,\n",
    "                    \"fairness_metrics\":experiment.fairness_metrics,\n",
    "                    \"experiment_object\":experiment,\n",
    "                    \"suppressed_variables\":output_proxies\n",
    "                })\n",
    "\n",
    "                # print(experiments[-1][\"name\"])\n",
    "                # print(f\"course: {course}, grade_threshold: {grade}\")\n",
    "                # print(f\"peformance: {experiment.performance_metrics}\")\n",
    "                # print(f\"fairness:   {experiment.fairness_metrics}\")\n",
    "                # print(f\"suppressed proxies {currently_suppressed}\")\n",
    "                # print()\n",
    "\n",
    "            # Fair PCA SES\n",
    "            experiment = Experiment(\n",
    "                data = data, \n",
    "                course = course, \n",
    "                grade_threshold = grade, \n",
    "                test_ratio = test_ratio, \n",
    "                random_state = random_state\n",
    "            )\n",
    "            experiment.fair_pca_data_prep()\n",
    "            experiment.train_and_test_pca(\n",
    "                model = model, \n",
    "                model_parameters= parameters,\n",
    "                eval=eval,\n",
    "                protected_features_to_suppress=[\"SES\"]\n",
    "            )\n",
    "\n",
    "            experiments.append({\n",
    "                \"name\":\"fairpca\",\n",
    "                \"grade_threshold\":grade,\n",
    "                \"course\":course,\n",
    "                \"model\":experiment.clf,\n",
    "                \"performance_metrics\":experiment.performance_metrics,\n",
    "                \"fairness_metrics\":experiment.fairness_metrics,\n",
    "                \"experiment_object\":experiment,\n",
    "                \"suppressed_variables\":\"SES\"\n",
    "            })\n",
    "            \n",
    "            # print(experiments[-1][\"name\"])\n",
    "            # print(f\"course: {course}, grade_threshold: {grade}\")\n",
    "            # print(f\"peformance: {experiment.performance_metrics}\")\n",
    "            # print(f\"fairness:   {experiment.fairness_metrics}\")\n",
    "            # print(f\"suppressed proxies SES\")\n",
    "            # print()\n",
    "\n",
    "    return experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>course</th>\n",
       "      <th>G_mean</th>\n",
       "      <th>SES_score</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>math</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>-0.733077</td>\n",
       "      <td>middle/rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>math</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>math</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>-1.234671</td>\n",
       "      <td>middle/rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>home</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>-0.323278</td>\n",
       "      <td>middle/rich</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob   \n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  \\\n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
       "\n",
       "   reason guardian  traveltime  studytime  failures schoolsup famsup paid   \n",
       "0  course   mother           2          2         0       yes     no   no  \\\n",
       "1  course   father           1          2         0        no    yes   no   \n",
       "2   other   mother           1          2         3       yes     no  yes   \n",
       "3    home   mother           1          3         0        no    yes  yes   \n",
       "4    home   father           1          2         0        no    yes  yes   \n",
       "\n",
       "  activities nursery higher internet romantic  famrel  freetime  goout  Dalc   \n",
       "0         no     yes    yes       no       no       4         3      4     1  \\\n",
       "1         no      no    yes      yes       no       5         3      3     1   \n",
       "2         no     yes    yes      yes       no       4         3      2     2   \n",
       "3        yes     yes    yes      yes      yes       3         2      2     1   \n",
       "4         no     yes    yes       no       no       4         3      2     1   \n",
       "\n",
       "   Walc  health  absences  G1  G2  G3 course     G_mean  SES_score   \n",
       "0     1       3         6   5   6   6   math   5.666667  -0.733077  \\\n",
       "1     1       3         4   5   5   6   math   5.333333   0.176471   \n",
       "2     3       3        10   7   8  10   math   8.333333   0.176471   \n",
       "3     1       5         2  15  14  15   math  14.666667  -1.234671   \n",
       "4     2       5         4   6  10  10   math   8.666667  -0.323278   \n",
       "\n",
       "           SES  \n",
       "0  middle/rich  \n",
       "1        lower  \n",
       "2        lower  \n",
       "3  middle/rich  \n",
       "4  middle/rich  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/all_students_and_SES.csv\")\n",
    "\n",
    "features = df.columns\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "For this paper we wanted to run 3(4) different types of experiments\n",
    "\n",
    "- Baseline\n",
    "\n",
    "Here we use all variables in the dataset except for G1, G2 and G3. G1 and G2 are discarded and G3 used as labels using a grade threshold, which is passing (10).\n",
    "Categorical variables are onehot encoded, but ordinal variables are kept as is. \n",
    "This experiment outlines what kind of bias was seen in the original paper this dataset is from where they used these variables.\n",
    "\n",
    "- Baseline (no proxies)\n",
    "\n",
    "Same as baseline, but we removed all of the variables we identify as strong proxies for SES.\n",
    "This experiment is a baseline for our FairPCA experiments, where we wanted to see if bias still would be present even without proxies.\n",
    "\n",
    "- FairPCA (Gradual)\n",
    "\n",
    "Same as Baseline with no proxies, except here we use FairPCA on the remaining variables. \n",
    "We gradually increase the amount of proxy variables used in FairPCA in descending order of factor score\n",
    "\n",
    "- FairPCA (SES)\n",
    "\n",
    "Same as Baseline with no proxies, except here we use FairPCA on the remaining variables. \n",
    "Here we only use the SES as protected group in Fair PCA to see if it is better than using proxies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_parameters = {\n",
    "    \"n_estimators\": [10, 20, 50, 75, 100],\n",
    "    \"max_depth\": [5,10,15,20, None]\n",
    "}\n",
    "svc_parameters = {\n",
    "    'kernel':[\"linear\",\"poly\",\"rbf\"],\n",
    "    'C':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'gamma':[\"scale\"]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not run the next two cells unless you want to wait 30 minutes for the experiments to run, just load the experiemts.pickle file in the cell further below in the results section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = run_experiments(\n",
    "    data=df,\n",
    "    grade_thresholds=[10],\n",
    "    test_ratio=0.4,\n",
    "    random_state=rs,\n",
    "    model=RandomForestClassifier,\n",
    "    parameters=rfc_parameters,\n",
    "    eval=\"f1\",\n",
    "    proxies_to_suppress=[\n",
    "        \"address_R\",\n",
    "        \"Medu_1\",\n",
    "        \"Fedu_1\",\n",
    "        \"Mjob_at_home\",\n",
    "        \"Fjob_other\",\n",
    "        \"traveltime_2\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"./results/experiments.pickle\")\n",
    "with open(file_path.absolute(), \"wb\") as file:\n",
    "    pickle.dump(experiments, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle file is list of dicts with these key value pairs\n",
    "\n",
    "- name : experiment type name\n",
    "- grade_threshold : Used to calculate target variable using G3. 10\n",
    "- course : Course the student was taking\n",
    "- model : The model used in the experiment\n",
    "- performance_metrics : Dict containing accuracy, recall and f1 score\n",
    "- fairness_metrics : DataFrame containing equalized odds metrics\n",
    "- experiment_obect : The object used to perform the experiment. Contains all of the data and principal compontants if used for PCA. See Experiment class at the top of the notebook\n",
    "- suppressed_variables : The proxy variables used in FairPCA as protected groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"./results/experiments.pickle\")\n",
    "with open(file_path.absolute(), \"rb\") as file:\n",
    "    experiments = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data = list()\n",
    "for experiment in experiments:\n",
    "\n",
    "\n",
    "    FPR_delta = np.abs(experiment[\"fairness_metrics\"][\"FPR\"][\"lower\"]-experiment[\"fairness_metrics\"][\"FPR\"][\"middle/rich\"])\n",
    "    TPR_delta = np.abs(experiment[\"fairness_metrics\"][\"TPR\"][\"lower\"]-experiment[\"fairness_metrics\"][\"TPR\"][\"middle/rich\"])\n",
    "\n",
    "    experiment_data.append({\n",
    "        \"Type\":                     experiment[\"name\"],\n",
    "        \"Grade threshold\":          experiment[\"grade_threshold\"],\n",
    "        \"Course\":                   experiment[\"course\"],\n",
    "        \"Accuracy\":                 experiment[\"performance_metrics\"][\"accuracy\"],\n",
    "        \"Recall\":                   experiment[\"performance_metrics\"][\"recall\"],\n",
    "        \"F1\":                       experiment[\"performance_metrics\"][\"f1\"],\n",
    "        \"FPR lower\":                experiment[\"fairness_metrics\"][\"FPR\"][\"lower\"],\n",
    "        \"FPR middle/rich\":          experiment[\"fairness_metrics\"][\"FPR\"][\"middle/rich\"],\n",
    "        \"FPR delta\":                FPR_delta,\n",
    "        \"TPR lower\":                experiment[\"fairness_metrics\"][\"TPR\"][\"lower\"],\n",
    "        \"TPR middle/rich\":          experiment[\"fairness_metrics\"][\"TPR\"][\"middle/rich\"],  \n",
    "        \"TPR delta\":                TPR_delta,\n",
    "        \"PCA protected variables\":  experiment[\"suppressed_variables\"]\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(experiment_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Grade threshold</th>\n",
       "      <th>Course</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>FPR lower</th>\n",
       "      <th>FPR middle/rich</th>\n",
       "      <th>FPR delta</th>\n",
       "      <th>TPR lower</th>\n",
       "      <th>TPR middle/rich</th>\n",
       "      <th>TPR delta</th>\n",
       "      <th>PCA protected variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.071970</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.062931</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_proxies</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>0.740506</td>\n",
       "      <td>0.944954</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.065948</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.926606</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.040948</td>\n",
       "      <td>[address_R]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>0.689873</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>[address_R, Medu_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>0.702532</td>\n",
       "      <td>0.954128</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.066288</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>[address_R, Medu_1, Fedu_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.028448</td>\n",
       "      <td>[address_R, Medu_1, Fedu_1, Mjob_at_home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.053448</td>\n",
       "      <td>[address_R, Medu_1, Fedu_1, Mjob_at_home, Fjob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.087069</td>\n",
       "      <td>[address_R, Medu_1, Fedu_1, Mjob_at_home, Fjob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>math</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.053448</td>\n",
       "      <td>SES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Type  Grade threshold Course  Accuracy    Recall        F1   \n",
       "0    baseline               10   math  0.727848  0.908257  0.821577  \\\n",
       "1  no_proxies               10   math  0.740506  0.944954  0.834008   \n",
       "2     fairpca               10   math  0.727848  0.926606  0.824490   \n",
       "3     fairpca               10   math  0.689873  0.899083  0.800000   \n",
       "4     fairpca               10   math  0.702532  0.954128  0.815686   \n",
       "5     fairpca               10   math  0.696203  0.917431  0.806452   \n",
       "6     fairpca               10   math  0.721519  0.935780  0.822581   \n",
       "7     fairpca               10   math  0.632911  0.798165  0.750000   \n",
       "8     fairpca               10   math  0.734177  0.935780  0.829268   \n",
       "\n",
       "   FPR lower  FPR middle/rich  FPR delta  TPR lower  TPR middle/rich   \n",
       "0     0.6250         0.696970   0.071970   0.862069           0.9250  \\\n",
       "1     0.6875         0.727273   0.039773   0.896552           0.9625   \n",
       "2     0.7500         0.696970   0.053030   0.896552           0.9375   \n",
       "3     0.7500         0.787879   0.037879   0.862069           0.9125   \n",
       "4     0.8125         0.878788   0.066288   0.965517           0.9500   \n",
       "5     0.7500         0.818182   0.068182   0.896552           0.9250   \n",
       "6     0.7500         0.757576   0.007576   0.896552           0.9500   \n",
       "7     0.5000         0.848485   0.348485   0.862069           0.7750   \n",
       "8     0.6875         0.727273   0.039773   0.896552           0.9500   \n",
       "\n",
       "   TPR delta                            PCA protected variables  \n",
       "0   0.062931                                               None  \n",
       "1   0.065948                                               None  \n",
       "2   0.040948                                        [address_R]  \n",
       "3   0.050431                                [address_R, Medu_1]  \n",
       "4   0.015517                        [address_R, Medu_1, Fedu_1]  \n",
       "5   0.028448          [address_R, Medu_1, Fedu_1, Mjob_at_home]  \n",
       "6   0.053448  [address_R, Medu_1, Fedu_1, Mjob_at_home, Fjob...  \n",
       "7   0.087069  [address_R, Medu_1, Fedu_1, Mjob_at_home, Fjob...  \n",
       "8   0.053448                                                SES  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[(df_results[\"Grade threshold\"] == 10) & (df_results[\"Course\"]==\"math\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Grade threshold</th>\n",
       "      <th>Course</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>FPR lower</th>\n",
       "      <th>FPR middle/rich</th>\n",
       "      <th>FPR delta</th>\n",
       "      <th>TPR lower</th>\n",
       "      <th>TPR middle/rich</th>\n",
       "      <th>TPR delta</th>\n",
       "      <th>PCA protected variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>baseline</td>\n",
       "      <td>10</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.977169</td>\n",
       "      <td>0.910638</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>0.039596</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>no_proxies</td>\n",
       "      <td>10</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.995434</td>\n",
       "      <td>0.921776</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[address_R]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.990868</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>[address_R, Medu_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[address_R, Medu_1, Fedu_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.990868</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>[address_R, Medu_1, Fedu_1, Mjob_at_home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.913319</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.148485</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>0.016067</td>\n",
       "      <td>[address_R, Medu_1, Fedu_1, Mjob_at_home, Fjob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.990868</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>[address_R, Medu_1, Fedu_1, Mjob_at_home, Fjob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fairpca</td>\n",
       "      <td>10</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.057576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Type  Grade threshold      Course  Accuracy    Recall        F1   \n",
       "9     baseline               10  portuguese  0.838462  0.977169  0.910638  \\\n",
       "10  no_proxies               10  portuguese  0.857692  0.995434  0.921776   \n",
       "11     fairpca               10  portuguese  0.846154  1.000000  0.916318   \n",
       "12     fairpca               10  portuguese  0.838462  0.990868  0.911765   \n",
       "13     fairpca               10  portuguese  0.846154  1.000000  0.916318   \n",
       "14     fairpca               10  portuguese  0.838462  0.990868  0.911765   \n",
       "15     fairpca               10  portuguese  0.842308  0.986301  0.913319   \n",
       "16     fairpca               10  portuguese  0.838462  0.990868  0.911765   \n",
       "17     fairpca               10  portuguese  0.850000  1.000000  0.918239   \n",
       "\n",
       "    FPR lower  FPR middle/rich  FPR delta  TPR lower  TPR middle/rich   \n",
       "9    0.866667         1.000000   0.133333   0.952941         0.992537  \\\n",
       "10   0.833333         1.000000   0.166667   0.988235         1.000000   \n",
       "11   1.000000         0.909091   0.090909   1.000000         1.000000   \n",
       "12   1.000000         0.909091   0.090909   1.000000         0.985075   \n",
       "13   1.000000         0.909091   0.090909   1.000000         1.000000   \n",
       "14   1.000000         0.909091   0.090909   0.976471         1.000000   \n",
       "15   0.966667         0.818182   0.148485   0.976471         0.992537   \n",
       "16   1.000000         0.909091   0.090909   0.988235         0.992537   \n",
       "17   0.966667         0.909091   0.057576   1.000000         1.000000   \n",
       "\n",
       "    TPR delta                            PCA protected variables  \n",
       "9    0.039596                                               None  \n",
       "10   0.011765                                               None  \n",
       "11   0.000000                                        [address_R]  \n",
       "12   0.014925                                [address_R, Medu_1]  \n",
       "13   0.000000                        [address_R, Medu_1, Fedu_1]  \n",
       "14   0.023529          [address_R, Medu_1, Fedu_1, Mjob_at_home]  \n",
       "15   0.016067  [address_R, Medu_1, Fedu_1, Mjob_at_home, Fjob...  \n",
       "16   0.004302  [address_R, Medu_1, Fedu_1, Mjob_at_home, Fjob...  \n",
       "17   0.000000                                                SES  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[(df_results[\"Grade threshold\"] == 10) & (df_results[\"Course\"]==\"portuguese\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algofair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
